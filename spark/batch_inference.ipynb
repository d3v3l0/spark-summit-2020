{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"resources/inference.png\" align='center' width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "    .config(\"spark.jars.packages\", \"io.delta:delta-core_2.11:0.6.0\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.addPyFile(\"/usr/lib/spark/jars/delta-core_2.11-0.6.0.jar\")\n",
    "from delta.tables import *\n",
    "# Enable Arrow support.\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"128\")\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4020388757774f2288e69889956a7387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tarfile\n",
    "import time\n",
    "import zipfile\n",
    "\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:\n",
    "    from urllib import urlretrieve\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import default_loader  # private API\n",
    "\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, monotonically_increasing_id\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "import determined as det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading a Checkpoint from Determined\n",
    "\n",
    "<img src=\"resources/checkpoint.png\" align='center' width=500 />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c8995e7c2e4adf80c0966bbdae776f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from determined.experimental import Determined\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "checkpoint = Determined(master=\"ec2-54-185-44-13.us-west-2.compute.amazonaws.com:8080\").get_experiment(2).top_checkpoint()\n",
    "model = checkpoint.load(path=\"/home/.config/ckpt\", map_location=torch.device('cpu'))\n",
    "\n",
    "b_state_dict = sc.broadcast(model.state_dict())\n",
    "\n",
    "def get_model_for_eval():\n",
    "    \"\"\"Gets the broadcasted model.\"\"\"\n",
    "    model = fasterrcnn_resnet50_fpn(pretrained=False, pretrained_backbone=False)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 20)\n",
    "    model.load_state_dict(b_state_dict.value)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load inference Dataset\n",
    "\n",
    "<img src=\"resources/load_data.png\" align='center' width=500 />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1367a0c1a0540f3bca3ffa034d751f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|               image|                 key|\n",
      "+--------------------+--------------------+\n",
      "|[FF D8 FF E0 00 1...|v1/JPEGImages/200...|\n",
      "|[FF D8 FF E0 00 1...|v1/JPEGImages/200...|\n",
      "|[FF D8 FF E0 00 1...|v1/JPEGImages/200...|\n",
      "|[FF D8 FF E0 00 1...|v1/JPEGImages/200...|\n",
      "|[FF D8 FF E0 00 1...|v1/JPEGImages/200...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "1000"
     ]
    }
   ],
   "source": [
    "images_df = spark.read.format(\"delta\").option(\"versionAsOf\", 0).load(\"s3://david-voc-delta/val/\")\n",
    "\n",
    "images_df = images_df.select(col('image'), col('key'))\n",
    "images_df.show(5)\n",
    "images_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Inference Process\n",
    "\n",
    "We need to tell Spark how to load the data and perform inference.  For actual inference, we use a Pandas UDF to efficiently batch the data and minimize the time spent loading the model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4c668201d814284aff6638832ff6a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "\n",
    "class VOCDataset(Dataset):\n",
    "  def __init__(self, images):\n",
    "    self.raw_images = images\n",
    "    \n",
    "    transforms = []\n",
    "    transforms.append(ToTensor())\n",
    "    self.transform = Compose(transforms)\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.raw_images)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    raw_image = self.raw_images[index]\n",
    "    image = Image.open(io.BytesIO(raw_image)).convert('RGB')\n",
    "    image = self.transform(image)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522a81409e734a08a1fd4e1eb58581b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from pyspark.sql.types import StructType, StructField, FloatType, ArrayType, IntegerType, StringType\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return list(batch)\n",
    "\n",
    "def predict_batch(raw_images):\n",
    "    os.environ['LRU_CACHE_CAPACITY'] = '1'\n",
    "    ds = VOCDataset(list(raw_images))\n",
    "    loader = torch.utils.data.DataLoader(ds, batch_size=2, num_workers=8, shuffle=False, collate_fn=collate_fn)\n",
    "    model = get_model_for_eval()\n",
    "    all_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for images in loader:\n",
    "            predictions = model(images)\n",
    "            for prediction in predictions:\n",
    "                bs = prediction['boxes'].cpu().numpy().flatten().tolist()\n",
    "                ls = prediction['labels'].cpu().numpy().astype(np.float32).tolist()\n",
    "                ss = prediction['scores'].cpu().numpy().tolist()\n",
    "                all_predictions.append([bs, ls, ss])\n",
    "#     return pd.Series([len(ds)] * len(ds))\n",
    "    return pd.Series(all_predictions)\n",
    "\n",
    "predict_udf = pandas_udf(ArrayType(ArrayType(FloatType())), PandasUDFType.SCALAR)(predict_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions\n",
    "\n",
    "<img src=\"resources/preds.png\" align='center' width=300 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da56594a90c24fe0afc78b078c5c48ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_df = images_df.repartition(40)\n",
    "predictions_df = input_df.select(col('key'), predict_udf(col('image')).alias(\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089a95828dbd4b7387ae64a4941e9c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(\n",
    "  predictions_df\n",
    "  .write\n",
    "  .format(\"delta\")\n",
    "  .mode(\"overwrite\")\n",
    "  .option(\"compression\", \"gzip\")\n",
    "  .save(\"s3://david-voc-predictions/preds\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the Predictions\n",
    "\n",
    "We can then inspect the predictions on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3eca5919b004bceacf556bcc1a98c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                 key|          prediction|\n",
      "+--------------------+--------------------+\n",
      "|v1/JPEGImages/201...|[[19.41631, 86.18...|\n",
      "|v1/JPEGImages/201...|[[32.854958, 25.9...|\n",
      "|v1/JPEGImages/201...|[[396.55264, 160....|\n",
      "|v1/JPEGImages/201...|[[36.59609, 36.16...|\n",
      "|v1/JPEGImages/201...|[[167.91513, 23.1...|\n",
      "|v1/JPEGImages/201...|[[97.14731, 22.16...|\n",
      "|v1/JPEGImages/201...|[[308.70505, 266....|\n",
      "|v1/JPEGImages/200...|[[130.96548, 29.4...|\n",
      "|v1/JPEGImages/200...|[[204.10103, 67.2...|\n",
      "|v1/JPEGImages/200...|[[106.18939, 116....|\n",
      "|v1/JPEGImages/200...|[[41.099865, 133....|\n",
      "|v1/JPEGImages/200...|[[89.92501, 40.92...|\n",
      "|v1/JPEGImages/200...|[[54.83442, 0.0, ...|\n",
      "|v1/JPEGImages/200...|[[145.85356, 0.0,...|\n",
      "|v1/JPEGImages/200...|[[213.14555, 117....|\n",
      "|v1/JPEGImages/201...|[[258.44434, 203....|\n",
      "|v1/JPEGImages/201...|[[238.99425, 99.7...|\n",
      "|v1/JPEGImages/201...|[[299.58047, 127....|\n",
      "|v1/JPEGImages/200...|[[51.827614, 218....|\n",
      "|v1/JPEGImages/200...|[[321.14755, 22.7...|\n",
      "|v1/JPEGImages/200...|[[38.84112, 12.10...|\n",
      "|v1/JPEGImages/200...|[[241.57463, 21.4...|\n",
      "|v1/JPEGImages/200...|[[64.59806, 120.1...|\n",
      "|v1/JPEGImages/200...|[[194.72536, 0.0,...|\n",
      "|v1/JPEGImages/200...|[[97.662224, 47.2...|\n",
      "|v1/JPEGImages/200...|[[89.2948, 95.450...|\n",
      "|v1/JPEGImages/201...|[[75.85342, 172.3...|\n",
      "|v1/JPEGImages/201...|[[76.83297, 53.95...|\n",
      "|v1/JPEGImages/201...|[[36.367348, 123....|\n",
      "|v1/JPEGImages/201...|[[343.85715, 115....|\n",
      "|v1/JPEGImages/201...|[[220.8533, 174.7...|\n",
      "|v1/JPEGImages/201...|[[7.4039226, 141....|\n",
      "|v1/JPEGImages/201...|[[41.15203, 97.03...|\n",
      "|v1/JPEGImages/200...|[[68.136765, 88.6...|\n",
      "|v1/JPEGImages/200...|[[244.81554, 132....|\n",
      "|v1/JPEGImages/200...|[[27.15, 43.78587...|\n",
      "|v1/JPEGImages/200...|[[412.89203, 175....|\n",
      "|v1/JPEGImages/200...|[[195.77847, 97.9...|\n",
      "|v1/JPEGImages/200...|[[84.83505, 180.9...|\n",
      "|v1/JPEGImages/200...|[[165.54794, 172....|\n",
      "|v1/JPEGImages/201...|[[250.74535, 0.0,...|\n",
      "|v1/JPEGImages/201...|[[206.5688, 247.7...|\n",
      "|v1/JPEGImages/201...|[[171.15378, 30.0...|\n",
      "|v1/JPEGImages/201...|[[86.49368, 88.35...|\n",
      "|v1/JPEGImages/201...|[[35.636345, 23.0...|\n",
      "|v1/JPEGImages/201...|[[0.0, 24.135286,...|\n",
      "|v1/JPEGImages/200...|[[42.51936, 174.0...|\n",
      "|v1/JPEGImages/200...|[[198.4989, 165.8...|\n",
      "|v1/JPEGImages/200...|[[6.3337145, 64.2...|\n",
      "|v1/JPEGImages/200...|[[6.3433194, 19.7...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 50 rows"
     ]
    }
   ],
   "source": [
    "path =\"s3://david-voc-predictions/preds\"\n",
    "df = spark.read.format(\"delta\").load(path)\n",
    "df.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
